{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor \n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import joblib\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import hashlib\n",
    "\n",
    "import src.util as util"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = util.load_config()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load train set\n",
    "    x_train = util.pickle_load(params[\"train_feng_set_path\"][0])\n",
    "    y_train = util.pickle_load(params[\"train_feng_set_path\"][1])\n",
    "\n",
    "    return x_train, y_train\n",
    "\n",
    "def load_valid_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load valid set\n",
    "    x_valid = util.pickle_load(params[\"valid_feng_set_path\"][0])\n",
    "    y_valid = util.pickle_load(params[\"valid_feng_set_path\"][1])\n",
    "\n",
    "    return x_valid, y_valid\n",
    "\n",
    "def load_test_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load test set\n",
    "    x_test = util.pickle_load(params[\"test_feng_set_path\"][0])\n",
    "    y_test = util.pickle_load(params[\"test_feng_set_path\"][1])\n",
    "\n",
    "    return x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(params: dict) -> pd.DataFrame:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Loading dataset.\")\n",
    "\n",
    "    # Load train set\n",
    "    x_train, y_train = load_train_feng(params)\n",
    "\n",
    "    # Load valid set\n",
    "    x_valid, y_valid = load_valid_feng(params)\n",
    "\n",
    "    # Load test set\n",
    "    x_test, y_test = load_test_feng(params)\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Dataset loaded.\")\n",
    "\n",
    "    # Return the dataset\n",
    "    return x_train, y_train, x_valid, y_valid, x_test, y_test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Training Log Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_template() -> dict:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Creating training log template.\")\n",
    "    \n",
    "    # Template of training log\n",
    "    logger = {\n",
    "        \"model_name\" : [],\n",
    "        \"model_uid\" : [],\n",
    "        \"training_time\" : [],\n",
    "        \"training_date\" : [],\n",
    "        \"performance\" : [],\n",
    "        \"mse\" : [],\n",
    "        \"data_configurations\" : [],\n",
    "    }\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Training log template created.\")\n",
    "\n",
    "    # Return training log template\n",
    "    return logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_log_updater(current_log: dict, params: dict) -> list:\n",
    "    # Create copy of current log\n",
    "    current_log = copy.deepcopy(current_log)\n",
    "\n",
    "    # Path for training log file\n",
    "    log_path = params[\"training_log_path\"]\n",
    "\n",
    "    # Try to load training log file\n",
    "    try:\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "\n",
    "    # If file not found, create a new one\n",
    "    except FileNotFoundError as fe:\n",
    "        with open(log_path, \"w\") as file:\n",
    "            file.write(\"[]\")\n",
    "        file.close()\n",
    "\n",
    "        with open(log_path, \"r\") as file:\n",
    "            last_log = json.load(file)\n",
    "        file.close()\n",
    "    \n",
    "    # Add current log to previous log\n",
    "    last_log.append(current_log)\n",
    "\n",
    "    # Save updated log\n",
    "    with open(log_path, \"w\") as file:\n",
    "        json.dump(last_log, file)\n",
    "        file.close()\n",
    "\n",
    "    # Return log\n",
    "    return last_log"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Create Model Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_object(params: dict) -> list:\n",
    "    # Debug message\n",
    "    util.print_debug(\"Creating model objects.\")\n",
    "\n",
    "    # Create model objects\n",
    "\n",
    "    lnr = LinearRegression()\n",
    "    rdg = Ridge()\n",
    "    dct = DecisionTreeRegressor()\n",
    "    ran = RandomForestRegressor()\n",
    "    knn = KNeighborsRegressor()\n",
    "    xgb = XGBRegressor()\n",
    "\n",
    "    # Create list of model\n",
    "    list_of_model = [\n",
    "        { \"model_name\": lnr.__class__.__name__, \"model_object\": lnr, \"model_uid\": \"\"},\n",
    "        { \"model_name\": rdg.__class__.__name__, \"model_object\": rdg, \"model_uid\": \"\"},\n",
    "        { \"model_name\": dct.__class__.__name__, \"model_object\": dct, \"model_uid\": \"\"},\n",
    "        { \"model_name\": ran.__class__.__name__, \"model_object\": ran, \"model_uid\": \"\"},\n",
    "        { \"model_name\": knn.__class__.__name__, \"model_object\": knn, \"model_uid\": \"\"},\n",
    "        { \"model_name\": xgb.__class__.__name__, \"model_object\": xgb, \"model_uid\": \"\"}\n",
    "    ]\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Model objects created.\")\n",
    "\n",
    "    # Return the list of model\n",
    "    return list_of_model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Training Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_eval(configuration_model: str, params: dict, hyperparams_model: list = None):\n",
    "    # Load dataset\n",
    "    x_train, y_train, \\\n",
    "    x_valid, y_valid, \\\n",
    "    x_test, y_test = load_dataset(params)\n",
    "\n",
    "    # Variabel to store trained models\n",
    "    list_of_trained_model = dict()\n",
    "\n",
    "    # Create log template\n",
    "    training_log = training_log_template()\n",
    "\n",
    "    # Training for every data configuration\n",
    "    for config_data in x_train.columns:\n",
    "        # Debug message\n",
    "        util.print_debug(\"Training model based on configuration data: {}\".format(config_data))\n",
    "\n",
    "        # Create model objects\n",
    "        if hyperparams_model == None:\n",
    "            list_of_model = create_model_object(params)\n",
    "        else:\n",
    "            list_of_model = copy.deepcopy(hyperparams_model)\n",
    "\n",
    "        # Variabel to store trained model\n",
    "        trained_model = list()\n",
    "\n",
    "        # Load train data based on its configuration\n",
    "        x_train_data = x_train[[config_data]]\n",
    "        y_train_data = y_train\n",
    "\n",
    "        # Train each model by current dataset configuration\n",
    "        for model in list_of_model:\n",
    "            # Debug message\n",
    "            util.print_debug(\"Training model: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Training\n",
    "            training_time = util.time_stamp()\n",
    "            model[\"model_object\"].fit(x_train_data, y_train_data)\n",
    "            training_time = (util.time_stamp() - training_time).total_seconds()\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Evalutaing model: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Evaluation\n",
    "            y_predict = model[\"model_object\"].predict(x_valid[[config_data]])\n",
    "            performance = mean_squared_error(y_valid, y_predict)\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Logging: {}\".format(model[\"model_name\"]))\n",
    "\n",
    "            # Create UID\n",
    "            uid = hashlib.md5(str(training_time).encode()).hexdigest()\n",
    "\n",
    "            # Assign model's UID\n",
    "            model[\"model_uid\"] = uid\n",
    "\n",
    "            # Create training log data\n",
    "            training_log[\"model_name\"].append(\"{}-{}\".format(configuration_model, model[\"model_name\"]))\n",
    "            training_log[\"model_uid\"].append(uid)\n",
    "            training_log[\"training_time\"].append(training_time)\n",
    "            training_log[\"training_date\"].append(util.time_stamp())\n",
    "            training_log[\"performance\"].append(performance)\n",
    "            training_log[\"mse\"].append(performance)\n",
    "            training_log[\"data_configurations\"].append('no configuration')\n",
    "\n",
    "            # Collect current trained model\n",
    "            trained_model.append(copy.deepcopy(model))\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Model {} has been trained for configuration data {}.\".format(model[\"model_name\"], config_data))\n",
    "        \n",
    "        # Collect current trained list of model\n",
    "        list_of_trained_model[config_data] = copy.deepcopy(trained_model)\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"All combination models and configuration data has been trained.\")\n",
    "    \n",
    "    # Return list trained model\n",
    "    return list_of_trained_model, training_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_trained_model, training_log = train_eval(\"Baseline\", params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Choose Best Performance Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_production_model(list_of_model, training_log, params):\n",
    "    # Create copy list of model\n",
    "    list_of_model = copy.deepcopy(list_of_model)\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"Choosing model by metrics score.\")\n",
    "\n",
    "    # Create required predefined variabel\n",
    "    curr_production_model = None\n",
    "    prev_production_model = None\n",
    "    production_model_log = None\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Converting training log type of data from dict to dataframe.\")\n",
    "\n",
    "    # Convert dictionary to pandas for easy operation\n",
    "    training_log = pd.DataFrame(copy.deepcopy(training_log))\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Trying to load previous production model.\")\n",
    "\n",
    "    # Check if there is a previous production model\n",
    "    try:\n",
    "        prev_production_model = util.pickle_load(params[\"production_model_path\"])\n",
    "        util.print_debug(\"Previous production model loaded.\")\n",
    "\n",
    "    except FileNotFoundError as fe:\n",
    "        util.print_debug(\"No previous production model detected, choosing best model only from current trained model.\")\n",
    "\n",
    "    # If previous production model detected:\n",
    "    if prev_production_model != None:\n",
    "        # Debug message\n",
    "        util.print_debug(\"Loading validation data.\")\n",
    "        x_valid, y_valid = load_valid_feng(params)\n",
    "        \n",
    "        # Debug message\n",
    "        util.print_debug(\"Checking compatibilty previous production model's input with current train data's features.\")\n",
    "\n",
    "        # Check list features of previous production model and current dataset\n",
    "        production_model_features = set(prev_production_model[\"model_data\"][\"model_object\"].feature_names_in_)\n",
    "        current_dataset_features = set(x_valid.columns)\n",
    "        number_of_different_features = len((production_model_features - current_dataset_features) | (current_dataset_features - production_model_features))\n",
    "\n",
    "        # If feature matched:\n",
    "        if number_of_different_features == 0:\n",
    "            # Debug message\n",
    "            util.print_debug(\"Features compatible.\")\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Reassesing previous model performance using current validation data.\")\n",
    "\n",
    "            # Re-predict previous production model to provide valid metrics compared to other current models\n",
    "            y_pred = prev_production_model[\"model_data\"][\"model_object\"].predict(x_valid)\n",
    "\n",
    "            # Re-asses prediction result\n",
    "            eval_res = mean_squared_error(y_valid, y_pred)\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Assessing complete.\")\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Storing new metrics data to previous model structure.\")\n",
    "\n",
    "            # Update their performance log\n",
    "            prev_production_model[\"model_log\"][\"performance\"] = eval_res\n",
    "            prev_production_model[\"model_log\"][\"mse\"] = eval_res[\"mse\"]\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Adding previous model data to current training log and list of model\")\n",
    "\n",
    "            # Added previous production model log to current logs to compere who has the greatest f1 score\n",
    "            training_log = pd.concat([training_log, pd.DataFrame([prev_production_model[\"model_log\"]])])\n",
    "\n",
    "            # Added previous production model to current list of models to choose from if it has the greatest f1 score\n",
    "            list_of_model[\"prev_production_model\"] = [copy.deepcopy(prev_production_model[\"model_data\"])]\n",
    "        else:\n",
    "            # To indicate that we are not using previous production model\n",
    "            prev_production_model = None\n",
    "\n",
    "            # Debug message\n",
    "            util.print_debug(\"Different features between production model with current dataset is detected, ignoring production dataset.\")\n",
    "\n",
    "    # Debug message\n",
    "    util.print_debug(\"Sorting training log by mse and training time.\")\n",
    "\n",
    "    # Sort training log by mse and training time\n",
    "    best_model_log = training_log.sort_values([\"mse\", \"training_time\"], ascending = [False, True]).iloc[0]\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"Searching model data based on sorted training log.\")\n",
    "\n",
    "    # Get model object with greatest mse score macro avg by using UID\n",
    "    for configuration_data in list_of_model:\n",
    "        for model_data in list_of_model[configuration_data]:\n",
    "            if model_data[\"model_uid\"] == best_model_log[\"model_uid\"]:\n",
    "                curr_production_model = dict()\n",
    "                curr_production_model[\"model_data\"] = copy.deepcopy(model_data)\n",
    "                curr_production_model[\"model_log\"] = copy.deepcopy(best_model_log.to_dict())\n",
    "                curr_production_model[\"model_log\"][\"model_name\"] = \"Production-{}\".format(curr_production_model[\"model_data\"][\"model_name\"])\n",
    "                curr_production_model[\"model_log\"][\"training_date\"] = str(curr_production_model[\"model_log\"][\"training_date\"])\n",
    "                production_model_log = training_log_updater(curr_production_model[\"model_log\"], params)\n",
    "                break\n",
    "    \n",
    "    # In case UID not found\n",
    "    if curr_production_model == None:\n",
    "        raise RuntimeError(\"The best model not found in your list of model.\")\n",
    "    \n",
    "    # Debug message\n",
    "    util.print_debug(\"Model chosen.\")\n",
    "\n",
    "    # Dump chosen production model\n",
    "    util.pickle_dump(curr_production_model, params[\"production_model_path\"])\n",
    "    \n",
    "    # Return current chosen production model, log of production models and current training log\n",
    "    return curr_production_model, production_model_log, training_log\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, production_model_log, training_logs = get_production_model(list_of_trained_model, training_log, params)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grid_params(model_name: str) -> dict:\n",
    "\n",
    "    # Define models parameters\n",
    "    grid_params_xgb = {\n",
    "        \"n_estimators\": [50, 100, 200, 300, 400, 500]\n",
    "    }\n",
    "    grid_params_dct = {\n",
    "        \"criterion\": [\"squared_error\", \"friedman_mse\", \"absolute_error\", \"poisson\"],\n",
    "        \"min_samples_split\": [1, 2, 4, 6, 10, 15, 20, 25],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 6, 10, 15, 20, 25]\n",
    "    }\n",
    "    grid_params_knn = {\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"algorithm\": [\"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "        \"n_neighbors\": [2, 3, 4, 5, 6, 10, 15, 20, 25],\n",
    "        \"leaf_size\": [2, 3, 4, 5, 6, 10, 15, 20, 25],\n",
    "    }\n",
    "    grid_params_ridge = {\n",
    "        \"alpha\": [0.01, 0.05, 0.1, 0.15, 0.2, 0.3, 0.6, 0.9, 1],\n",
    "        \"solver\": [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"],\n",
    "    }\n",
    "    grid_params_rfr = {\n",
    "        \"n_estimators\": [50, 100, 200, 300, 400, 500],\n",
    "        \"criterion\": [\"mse\", \"mae\"],\n",
    "        \"min_samples_split\": [1, 2, 4, 6, 10, 15, 20, 25],\n",
    "        \"min_samples_leaf\": [1, 2, 4, 6, 10, 15, 20, 25]\n",
    "    }\n",
    "\n",
    "    # Combine all models parameters into one\n",
    "    grid_params = {\n",
    "        \"XGBRegressor\": grid_params_xgb,\n",
    "        \"DecisionTreeRegressor\": grid_params_dct,\n",
    "        \"KNeighborsRegressor\": grid_params_knn,\n",
    "        \"Ridge\": grid_params_ridge,\n",
    "        \"RandomForestRegressor\": grid_params_rfr\n",
    "    }\n",
    "\n",
    "    # Return distribution of model parameters\n",
    "    return grid_params[model_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "def hyper_params_tuning(model: dict) -> list:\n",
    "    # Create copy of current best baseline model\n",
    "    model = copy.deepcopy(model)\n",
    "\n",
    "    # Create model's parameter distribution\n",
    "    grid_params = create_grid_params(model[\"model_data\"][\"model_name\"])\n",
    "\n",
    "    # Create model object\n",
    "    model_gsc = GridSearchCV(model[\"model_data\"][\"model_object\"], grid_params, n_jobs = -1)\n",
    "    model_data = {\n",
    "        \"model_name\": model[\"model_data\"][\"model_name\"],\n",
    "        \"model_object\": model_gsc,\n",
    "        \"model_uid\": \"\"\n",
    "    }\n",
    "    \n",
    "    # Return model object\n",
    "    return [model_data]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:18.744462 Loading dataset.\n",
      "2023-04-12 08:08:18.749864 Dataset loaded.\n",
      "2023-04-12 08:08:18.749886 Creating training log template.\n",
      "2023-04-12 08:08:18.749891 Training log template created.\n",
      "2023-04-12 08:08:18.749944 Training model based on configuration data: INTD.JK\n",
      "2023-04-12 08:08:18.751516 Training model: DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-0.98018938 -0.98018938 -0.83390445 -0.77358818 -0.3991646  -0.36746513\n",
      " -0.37878033 -0.35776426 -0.40581633 -0.40581633 -0.40581633 -0.38032512\n",
      " -0.24877041 -0.22617402 -0.2292202  -0.19287802 -0.21660628 -0.21660628\n",
      " -0.21660628 -0.21660628 -0.20231007 -0.16714919 -0.17508896 -0.17154723\n",
      " -0.22325842 -0.22325842 -0.22325842 -0.22325842 -0.22325842 -0.19304027\n",
      " -0.20464097 -0.20087261 -0.12952385 -0.12952385 -0.12952385 -0.12952385\n",
      " -0.12952385 -0.12952385 -0.12952385 -0.12414873 -0.08775159 -0.08775159\n",
      " -0.08775159 -0.08775159 -0.08775159 -0.08775159 -0.08775159 -0.08775159\n",
      " -0.08974056 -0.08974056 -0.08974056 -0.08974056 -0.08974056 -0.08974056\n",
      " -0.08974056 -0.08974056 -0.0438605  -0.0438605  -0.0438605  -0.0438605\n",
      " -0.0438605  -0.0438605  -0.0438605  -0.0438605  -0.98018938 -0.98018938\n",
      " -0.83390445 -0.77358818 -0.3991646  -0.36746513 -0.37878033 -0.35776426\n",
      " -0.40581633 -0.40581633 -0.40581633 -0.38032512 -0.24877041 -0.22617402\n",
      " -0.2292202  -0.19287802 -0.21660628 -0.21660628 -0.21660628 -0.21660628\n",
      " -0.20231007 -0.16714919 -0.17508896 -0.17154723 -0.22325842 -0.22325842\n",
      " -0.22325842 -0.22325842 -0.22325842 -0.19304027 -0.20464097 -0.20087261\n",
      " -0.12952385 -0.12952385 -0.12952385 -0.12952385 -0.12952385 -0.12952385\n",
      " -0.12952385 -0.12414873 -0.08775159 -0.08775159 -0.08775159 -0.08775159\n",
      " -0.08775159 -0.08775159 -0.08775159 -0.08775159 -0.08974056 -0.08974056\n",
      " -0.08974056 -0.08974056 -0.08974056 -0.08974056 -0.08974056 -0.08974056\n",
      " -0.0438605  -0.0438605  -0.0438605  -0.0438605  -0.0438605  -0.0438605\n",
      " -0.0438605  -0.0438605  -0.99006102 -0.99006102 -0.76390239 -0.54417298\n",
      " -0.52088284 -0.52441244 -0.52302238 -0.44792147 -0.46638491 -0.46638491\n",
      " -0.46638491 -0.31589052 -0.21531778 -0.21190216 -0.24628497 -0.21477198\n",
      " -0.14769452 -0.14769452 -0.14769452 -0.14769452 -0.1198557  -0.07527307\n",
      " -0.11182736 -0.08515937 -0.11861411 -0.11861411 -0.11861411 -0.11861411\n",
      " -0.11861411 -0.09243118 -0.12303507 -0.09048273 -0.12840672 -0.12840672\n",
      " -0.12840672 -0.12840672 -0.12840672 -0.12840672 -0.12840672 -0.12112334\n",
      " -0.09397246 -0.09397246 -0.09397246 -0.09397246 -0.09397246 -0.09397246\n",
      " -0.09397246 -0.09397246 -0.05443803 -0.05443803 -0.05443803 -0.05443803\n",
      " -0.05443803 -0.05443803 -0.05443803 -0.05443803 -0.05410859 -0.05410859\n",
      " -0.05410859 -0.05410859 -0.05410859 -0.05410859 -0.05410859 -0.05410859\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:20.148693 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:20.149575 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:20.150204 Model DecisionTreeRegressor has been trained for configuration data INTD.JK.\n",
      "2023-04-12 08:08:20.150673 Training model based on configuration data: ULTJ.JK\n",
      "2023-04-12 08:08:20.150943 Training model: DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-0.58316232 -0.58316232 -0.54474741 -0.57025824 -0.5042692  -0.47511504\n",
      " -0.44942987 -0.40879152 -0.65191038 -0.65191038 -0.65191038 -0.53108091\n",
      " -0.48794975 -0.46547332 -0.43978814 -0.3991498  -0.15753786 -0.15753786\n",
      " -0.15753786 -0.15753786 -0.14720539 -0.13884542 -0.13076615 -0.12158513\n",
      " -0.08443777 -0.08443777 -0.08443777 -0.08443777 -0.08443777 -0.08705027\n",
      " -0.08496232 -0.07455035 -0.01161136 -0.01161136 -0.01161136 -0.01161136\n",
      " -0.01161136 -0.01161136 -0.01161136 -0.01470615 -0.03998135 -0.03998135\n",
      " -0.03998135 -0.03998135 -0.03998135 -0.03998135 -0.03998135 -0.03998135\n",
      " -0.04192331 -0.04192331 -0.04192331 -0.04192331 -0.04192331 -0.04192331\n",
      " -0.04192331 -0.04192331 -0.02064605 -0.02064605 -0.02064605 -0.02064605\n",
      " -0.02064605 -0.02064605 -0.02064605 -0.02064605 -0.58316232 -0.58316232\n",
      " -0.54474741 -0.57025824 -0.5042692  -0.47511504 -0.44942987 -0.40879152\n",
      " -0.65191038 -0.65191038 -0.65191038 -0.53108091 -0.48794975 -0.46547332\n",
      " -0.43978814 -0.3991498  -0.15753786 -0.15753786 -0.15753786 -0.15753786\n",
      " -0.14720539 -0.13884542 -0.13076615 -0.12158513 -0.08443777 -0.08443777\n",
      " -0.08443777 -0.08443777 -0.08443777 -0.08705027 -0.08496232 -0.07455035\n",
      " -0.01161136 -0.01161136 -0.01161136 -0.01161136 -0.01161136 -0.01161136\n",
      " -0.01161136 -0.01470615 -0.03998135 -0.03998135 -0.03998135 -0.03998135\n",
      " -0.03998135 -0.03998135 -0.03998135 -0.03998135 -0.04192331 -0.04192331\n",
      " -0.04192331 -0.04192331 -0.04192331 -0.04192331 -0.04192331 -0.04192331\n",
      " -0.02064605 -0.02064605 -0.02064605 -0.02064605 -0.02064605 -0.02064605\n",
      " -0.02064605 -0.02064605 -0.58298545 -0.58298545 -0.51660803 -0.50983823\n",
      " -0.33789796 -0.3280486  -0.3467275  -0.32567021 -0.59660379 -0.59660379\n",
      " -0.59660379 -0.46655482 -0.36167797 -0.31748849 -0.33595291 -0.31468044\n",
      " -0.17368894 -0.17368894 -0.17368894 -0.17368894 -0.14230493 -0.10220776\n",
      " -0.10242495 -0.06872929 -0.05701729 -0.05701729 -0.05701729 -0.05701729\n",
      " -0.05701729 -0.04851651 -0.05172406 -0.06400861 -0.03661364 -0.03661364\n",
      " -0.03661364 -0.03661364 -0.03661364 -0.03661364 -0.03661364 -0.03165151\n",
      " -0.06190437 -0.06190437 -0.06190437 -0.06190437 -0.06190437 -0.06190437\n",
      " -0.06190437 -0.06190437 -0.04682524 -0.04682524 -0.04682524 -0.04682524\n",
      " -0.04682524 -0.04682524 -0.04682524 -0.04682524 -0.03557011 -0.03557011\n",
      " -0.03557011 -0.03557011 -0.03557011 -0.03557011 -0.03557011 -0.03557011\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:20.448915 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:20.449751 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:20.450280 Model DecisionTreeRegressor has been trained for configuration data ULTJ.JK.\n",
      "2023-04-12 08:08:20.450759 Training model based on configuration data: PDES.JK\n",
      "2023-04-12 08:08:20.450995 Training model: DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-0.94359205 -0.94359205 -0.61977524 -0.60364187 -0.48496481 -0.41747902\n",
      " -0.4222918  -0.40687654 -0.51604023 -0.51604023 -0.51604023 -0.51909208\n",
      " -0.52226892 -0.46311785 -0.4371842  -0.41478654 -0.40421482 -0.40421482\n",
      " -0.40421482 -0.40421482 -0.41112571 -0.38124638 -0.35734433 -0.35242637\n",
      " -0.30450421 -0.30450421 -0.30450421 -0.30450421 -0.30450421 -0.29886996\n",
      " -0.28369281 -0.26605988 -0.15464822 -0.15464822 -0.15464822 -0.15464822\n",
      " -0.15464822 -0.15464822 -0.15464822 -0.14120325 -0.0550338  -0.0550338\n",
      " -0.0550338  -0.0550338  -0.0550338  -0.0550338  -0.0550338  -0.0550338\n",
      " -0.04325431 -0.04325431 -0.04325431 -0.04325431 -0.04325431 -0.04325431\n",
      " -0.04325431 -0.04325431 -0.02243487 -0.02243487 -0.02243487 -0.02243487\n",
      " -0.02243487 -0.02243487 -0.02243487 -0.02243487 -0.94359205 -0.94359205\n",
      " -0.61977524 -0.60364187 -0.48496481 -0.41747902 -0.4222918  -0.40687654\n",
      " -0.51604023 -0.51604023 -0.51604023 -0.51909208 -0.52226892 -0.46311785\n",
      " -0.4371842  -0.41478654 -0.40421482 -0.40421482 -0.40421482 -0.40421482\n",
      " -0.41112571 -0.38124638 -0.35734433 -0.35242637 -0.30450421 -0.30450421\n",
      " -0.30450421 -0.30450421 -0.30450421 -0.29886996 -0.28369281 -0.26605988\n",
      " -0.15464822 -0.15464822 -0.15464822 -0.15464822 -0.15464822 -0.15464822\n",
      " -0.15464822 -0.14120325 -0.0550338  -0.0550338  -0.0550338  -0.0550338\n",
      " -0.0550338  -0.0550338  -0.0550338  -0.0550338  -0.04325431 -0.04325431\n",
      " -0.04325431 -0.04325431 -0.04325431 -0.04325431 -0.04325431 -0.04325431\n",
      " -0.02243487 -0.02243487 -0.02243487 -0.02243487 -0.02243487 -0.02243487\n",
      " -0.02243487 -0.02243487 -0.93631659 -0.93631659 -0.46357692 -0.46600616\n",
      " -0.32049225 -0.31698976 -0.29135166 -0.27389166 -0.48014068 -0.48014068\n",
      " -0.48014068 -0.3446841  -0.21933666 -0.21756332 -0.20436659 -0.18617719\n",
      " -0.15679534 -0.15679534 -0.15679534 -0.15679534 -0.14344784 -0.12523868\n",
      " -0.07579419 -0.06436472 -0.13656468 -0.13656468 -0.13656468 -0.13656468\n",
      " -0.13656468 -0.13217058 -0.0595212  -0.06105801 -0.0295607  -0.0295607\n",
      " -0.0295607  -0.0295607  -0.0295607  -0.0295607  -0.0295607  -0.03278\n",
      " -0.02335437 -0.02335437 -0.02335437 -0.02335437 -0.02335437 -0.02335437\n",
      " -0.02335437 -0.02335437 -0.00848283 -0.00848283 -0.00848283 -0.00848283\n",
      " -0.00848283 -0.00848283 -0.00848283 -0.00848283 -0.00685423 -0.00685423\n",
      " -0.00685423 -0.00685423 -0.00685423 -0.00685423 -0.00685423 -0.00685423\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:20.739606 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:20.740236 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:20.740909 Model DecisionTreeRegressor has been trained for configuration data PDES.JK.\n",
      "2023-04-12 08:08:20.741485 Training model based on configuration data: KICI.JK\n",
      "2023-04-12 08:08:20.741806 Training model: DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-1.28164145e+00 -1.28164145e+00 -1.25328214e+00 -9.39023760e-01\n",
      " -4.43557030e-01 -4.11487367e-01 -3.03229531e-01 -2.96761616e-01\n",
      " -6.27991273e-01 -6.27991273e-01 -6.27991273e-01 -5.08752904e-01\n",
      " -4.05373929e-01 -3.29035622e-01 -2.31351765e-01 -2.28362241e-01\n",
      " -2.47719459e-01 -2.47719459e-01 -2.47719459e-01 -2.47719459e-01\n",
      " -2.18963058e-01 -2.04925945e-01 -1.16485461e-01 -1.28985071e-01\n",
      " -1.66648375e-01 -1.66648375e-01 -1.66648375e-01 -1.66648375e-01\n",
      " -1.66648375e-01 -1.64719941e-01 -1.47759938e-01 -1.55742316e-01\n",
      " -1.17130516e-01 -1.17130516e-01 -1.17130516e-01 -1.17130516e-01\n",
      " -1.17130516e-01 -1.17130516e-01 -1.17130516e-01 -1.08144817e-01\n",
      " -8.12849838e-02 -8.12849838e-02 -8.12849838e-02 -8.12849838e-02\n",
      " -8.12849838e-02 -8.12849838e-02 -8.12849838e-02 -8.12849838e-02\n",
      " -1.48376136e-02 -1.48376136e-02 -1.48376136e-02 -1.48376136e-02\n",
      " -1.48376136e-02 -1.48376136e-02 -1.48376136e-02 -1.48376136e-02\n",
      " -5.93936685e-03 -5.93936685e-03 -5.93936685e-03 -5.93936685e-03\n",
      " -5.93936685e-03 -5.93936685e-03 -5.93936685e-03 -5.93936685e-03\n",
      " -1.28164145e+00 -1.28164145e+00 -1.25328214e+00 -9.39023760e-01\n",
      " -4.43557030e-01 -4.11487367e-01 -3.03229531e-01 -2.96761616e-01\n",
      " -6.27991273e-01 -6.27991273e-01 -6.27991273e-01 -5.08752904e-01\n",
      " -4.05373929e-01 -3.29035622e-01 -2.31351765e-01 -2.28362241e-01\n",
      " -2.47719459e-01 -2.47719459e-01 -2.47719459e-01 -2.47719459e-01\n",
      " -2.18963058e-01 -2.04925945e-01 -1.16485461e-01 -1.28985071e-01\n",
      " -1.66648375e-01 -1.66648375e-01 -1.66648375e-01 -1.66648375e-01\n",
      " -1.66648375e-01 -1.64719941e-01 -1.47759938e-01 -1.55742316e-01\n",
      " -1.17130516e-01 -1.17130516e-01 -1.17130516e-01 -1.17130516e-01\n",
      " -1.17130516e-01 -1.17130516e-01 -1.17130516e-01 -1.08144817e-01\n",
      " -8.12849838e-02 -8.12849838e-02 -8.12849838e-02 -8.12849838e-02\n",
      " -8.12849838e-02 -8.12849838e-02 -8.12849838e-02 -8.12849838e-02\n",
      " -1.48376136e-02 -1.48376136e-02 -1.48376136e-02 -1.48376136e-02\n",
      " -1.48376136e-02 -1.48376136e-02 -1.48376136e-02 -1.48376136e-02\n",
      " -5.93936685e-03 -5.93936685e-03 -5.93936685e-03 -5.93936685e-03\n",
      " -5.93936685e-03 -5.93936685e-03 -5.93936685e-03 -5.93936685e-03\n",
      " -1.27258059e+00 -1.27258059e+00 -1.18002654e+00 -6.77967920e-01\n",
      " -3.90443948e-01 -3.02199450e-01 -1.67218847e-01 -1.06083443e-01\n",
      " -4.48507695e-01 -4.48507695e-01 -4.48507695e-01 -4.02828876e-01\n",
      " -2.78433152e-01 -1.69123968e-01 -1.33038943e-01 -8.34812416e-02\n",
      " -7.03731270e-02 -7.03731270e-02 -7.03731270e-02 -7.03731270e-02\n",
      " -6.49351797e-02 -4.03339713e-02 -5.60096108e-03 -7.69651144e-03\n",
      " -2.31550728e-02 -2.31550728e-02 -2.31550728e-02 -2.31550728e-02\n",
      " -2.31550728e-02 -6.10784030e-03  1.94220330e-02  1.03375470e-02\n",
      " -1.46293501e-03 -1.46293501e-03 -1.46293501e-03 -1.46293501e-03\n",
      " -1.46293501e-03 -1.46293501e-03 -1.46293501e-03  1.21988653e-03\n",
      " -6.71217174e-03 -6.71217174e-03 -6.71217174e-03 -6.71217174e-03\n",
      " -6.71217174e-03 -6.71217174e-03 -6.71217174e-03 -6.71217174e-03\n",
      "  3.32763492e-02  3.32763492e-02  3.32763492e-02  3.32763492e-02\n",
      "  3.32763492e-02  3.32763492e-02  3.32763492e-02  3.32763492e-02\n",
      "  2.69420416e-02  2.69420416e-02  2.69420416e-02  2.69420416e-02\n",
      "  2.69420416e-02  2.69420416e-02  2.69420416e-02  2.69420416e-02\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan\n",
      "             nan             nan             nan             nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:21.108951 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:21.109585 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:21.110174 Model DecisionTreeRegressor has been trained for configuration data KICI.JK.\n",
      "2023-04-12 08:08:21.110769 Training model based on configuration data: PGJO.JK\n",
      "2023-04-12 08:08:21.111036 Training model: DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-0.53025689 -0.53025689 -0.51667866 -0.66333918 -0.52302324 -0.47298165\n",
      " -0.45957812 -0.4054512  -0.57422105 -0.57422105 -0.57422105 -0.57992612\n",
      " -0.46576708 -0.45493345 -0.44220785 -0.38808094 -0.3842314  -0.3842314\n",
      " -0.3842314  -0.3842314  -0.39823941 -0.38514442 -0.3731132  -0.32789996\n",
      " -0.19425371 -0.19425371 -0.19425371 -0.19425371 -0.19425371 -0.20228056\n",
      " -0.19551539 -0.1582338  -0.14725946 -0.14725946 -0.14725946 -0.14725946\n",
      " -0.14725946 -0.14725946 -0.14725946 -0.12984723 -0.10755091 -0.10755091\n",
      " -0.10755091 -0.10755091 -0.10755091 -0.10755091 -0.10755091 -0.10755091\n",
      " -0.10714556 -0.10714556 -0.10714556 -0.10714556 -0.10714556 -0.10714556\n",
      " -0.10714556 -0.10714556 -0.06017446 -0.06017446 -0.06017446 -0.06017446\n",
      " -0.06017446 -0.06017446 -0.06017446 -0.06017446 -0.53025689 -0.53025689\n",
      " -0.51667866 -0.66333918 -0.52302324 -0.47298165 -0.45957812 -0.4054512\n",
      " -0.57422105 -0.57422105 -0.57422105 -0.57992612 -0.46576708 -0.45493345\n",
      " -0.44220785 -0.38808094 -0.3842314  -0.3842314  -0.3842314  -0.3842314\n",
      " -0.39823941 -0.38514442 -0.3731132  -0.32789996 -0.19425371 -0.19425371\n",
      " -0.19425371 -0.19425371 -0.19425371 -0.20228056 -0.19551539 -0.1582338\n",
      " -0.14725946 -0.14725946 -0.14725946 -0.14725946 -0.14725946 -0.14725946\n",
      " -0.14725946 -0.12984723 -0.10755091 -0.10755091 -0.10755091 -0.10755091\n",
      " -0.10755091 -0.10755091 -0.10755091 -0.10755091 -0.10714556 -0.10714556\n",
      " -0.10714556 -0.10714556 -0.10714556 -0.10714556 -0.10714556 -0.10714556\n",
      " -0.06017446 -0.06017446 -0.06017446 -0.06017446 -0.06017446 -0.06017446\n",
      " -0.06017446 -0.06017446 -0.57507227 -0.57507227 -0.52524209 -0.53532589\n",
      " -0.43990892 -0.4308849  -0.22332876 -0.24499836 -0.53111383 -0.53111383\n",
      " -0.53111383 -0.48440362 -0.27519749 -0.18698647 -0.17670716 -0.20443955\n",
      " -0.27634331 -0.27634331 -0.27634331 -0.27634331 -0.28638871 -0.2759394\n",
      " -0.27292477 -0.21988992 -0.19063342 -0.19063342 -0.19063342 -0.19063342\n",
      " -0.19063342 -0.20226205 -0.20495209 -0.14368501 -0.15148891 -0.15148891\n",
      " -0.15148891 -0.15148891 -0.15148891 -0.15148891 -0.15148891 -0.14719283\n",
      " -0.07760868 -0.07760868 -0.07760868 -0.07760868 -0.07760868 -0.07760868\n",
      " -0.07760868 -0.07760868 -0.06126414 -0.06126414 -0.06126414 -0.06126414\n",
      " -0.06126414 -0.06126414 -0.06126414 -0.06126414 -0.03731864 -0.03731864\n",
      " -0.03731864 -0.03731864 -0.03731864 -0.03731864 -0.03731864 -0.03731864\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:21.414968 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:21.415587 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:21.416228 Model DecisionTreeRegressor has been trained for configuration data PGJO.JK.\n",
      "2023-04-12 08:08:21.416687 Training model based on configuration data: IKBI.JK\n",
      "2023-04-12 08:08:21.416922 Training model: DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-1.56677429 -1.56677429 -1.04707336 -0.99540933 -0.53929985 -0.3779511\n",
      " -0.36589033 -0.34343562 -0.83428385 -0.83428385 -0.83428385 -0.77198085\n",
      " -0.7229868  -0.46312503 -0.44112452 -0.4621224  -0.28909837 -0.28909837\n",
      " -0.28909837 -0.28909837 -0.28928701 -0.28257318 -0.28924019 -0.29999477\n",
      " -0.23460715 -0.23460715 -0.23460715 -0.23460715 -0.23460715 -0.22845914\n",
      " -0.23036385 -0.23383084 -0.11636003 -0.11636003 -0.11636003 -0.11636003\n",
      " -0.11636003 -0.11636003 -0.11636003 -0.11886945 -0.05067408 -0.05067408\n",
      " -0.05067408 -0.05067408 -0.05067408 -0.05067408 -0.05067408 -0.05067408\n",
      " -0.04916565 -0.04916565 -0.04916565 -0.04916565 -0.04916565 -0.04916565\n",
      " -0.04916565 -0.04916565 -0.07645886 -0.07645886 -0.07645886 -0.07645886\n",
      " -0.07645886 -0.07645886 -0.07645886 -0.07645886 -1.56677429 -1.56677429\n",
      " -1.04707336 -0.99540933 -0.53929985 -0.3779511  -0.36589033 -0.34343562\n",
      " -0.83428385 -0.83428385 -0.83428385 -0.77198085 -0.7229868  -0.46312503\n",
      " -0.44112452 -0.4621224  -0.28909837 -0.28909837 -0.28909837 -0.28909837\n",
      " -0.28928701 -0.28257318 -0.28924019 -0.29999477 -0.23460715 -0.23460715\n",
      " -0.23460715 -0.23460715 -0.23460715 -0.22845914 -0.23036385 -0.23383084\n",
      " -0.11636003 -0.11636003 -0.11636003 -0.11636003 -0.11636003 -0.11636003\n",
      " -0.11636003 -0.11886945 -0.05067408 -0.05067408 -0.05067408 -0.05067408\n",
      " -0.05067408 -0.05067408 -0.05067408 -0.05067408 -0.04916565 -0.04916565\n",
      " -0.04916565 -0.04916565 -0.04916565 -0.04916565 -0.04916565 -0.04916565\n",
      " -0.07645886 -0.07645886 -0.07645886 -0.07645886 -0.07645886 -0.07645886\n",
      " -0.07645886 -0.07645886 -1.57051845 -1.57051845 -1.03476698 -0.93911012\n",
      " -0.35434211 -0.28913314 -0.30017096 -0.26674666 -0.71956375 -0.71956375\n",
      " -0.71956375 -0.64523266 -0.46155483 -0.44925727 -0.43250708 -0.33929001\n",
      " -0.29823552 -0.29823552 -0.29823552 -0.29823552 -0.28525823 -0.19926571\n",
      " -0.20018764 -0.18228904 -0.08814917 -0.08814917 -0.08814917 -0.08814917\n",
      " -0.08814917 -0.07996981 -0.05051896 -0.05164677 -0.03728423 -0.03728423\n",
      " -0.03728423 -0.03728423 -0.03728423 -0.03728423 -0.03728423 -0.04100032\n",
      " -0.01797178 -0.01797178 -0.01797178 -0.01797178 -0.01797178 -0.01797178\n",
      " -0.01797178 -0.01797178 -0.01643494 -0.01643494 -0.01643494 -0.01643494\n",
      " -0.01643494 -0.01643494 -0.01643494 -0.01643494 -0.04677837 -0.04677837\n",
      " -0.04677837 -0.04677837 -0.04677837 -0.04677837 -0.04677837 -0.04677837\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:21.684361 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:21.685001 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:21.685670 Model DecisionTreeRegressor has been trained for configuration data IKBI.JK.\n",
      "2023-04-12 08:08:21.686110 Training model based on configuration data: APII.JK\n",
      "2023-04-12 08:08:21.686350 Training model: DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-0.6903553  -0.6903553  -0.60457937 -0.46875383 -0.36566486 -0.3134953\n",
      " -0.29352308 -0.28187572 -0.49044699 -0.49044699 -0.49044699 -0.38071854\n",
      " -0.35496203 -0.2792524  -0.272503   -0.24552091 -0.30176759 -0.30176759\n",
      " -0.30176759 -0.30176759 -0.31126292 -0.28696906 -0.27474269 -0.26249017\n",
      " -0.34208516 -0.34208516 -0.34208516 -0.34208516 -0.34208516 -0.33910079\n",
      " -0.34283063 -0.35237907 -0.195097   -0.195097   -0.195097   -0.195097\n",
      " -0.195097   -0.195097   -0.195097   -0.19390961 -0.08845931 -0.08845931\n",
      " -0.08845931 -0.08845931 -0.08845931 -0.08845931 -0.08845931 -0.08845931\n",
      " -0.09933024 -0.09933024 -0.09933024 -0.09933024 -0.09933024 -0.09933024\n",
      " -0.09933024 -0.09933024 -0.01982628 -0.01982628 -0.01982628 -0.01982628\n",
      " -0.01982628 -0.01982628 -0.01982628 -0.01982628 -0.6903553  -0.6903553\n",
      " -0.60457937 -0.46875383 -0.36566486 -0.3134953  -0.29352308 -0.28187572\n",
      " -0.49044699 -0.49044699 -0.49044699 -0.38071854 -0.35496203 -0.2792524\n",
      " -0.272503   -0.24552091 -0.30176759 -0.30176759 -0.30176759 -0.30176759\n",
      " -0.31126292 -0.28696906 -0.27474269 -0.26249017 -0.34208516 -0.34208516\n",
      " -0.34208516 -0.34208516 -0.34208516 -0.33910079 -0.34283063 -0.35237907\n",
      " -0.195097   -0.195097   -0.195097   -0.195097   -0.195097   -0.195097\n",
      " -0.195097   -0.19390961 -0.08845931 -0.08845931 -0.08845931 -0.08845931\n",
      " -0.08845931 -0.08845931 -0.08845931 -0.08845931 -0.09933024 -0.09933024\n",
      " -0.09933024 -0.09933024 -0.09933024 -0.09933024 -0.09933024 -0.09933024\n",
      " -0.01982628 -0.01982628 -0.01982628 -0.01982628 -0.01982628 -0.01982628\n",
      " -0.01982628 -0.01982628 -0.68068225 -0.68068225 -0.5538926  -0.54089727\n",
      " -0.33377874 -0.32948194 -0.32214017 -0.31163495 -0.5053831  -0.5053831\n",
      " -0.5053831  -0.48581112 -0.29934585 -0.27695951 -0.28572491 -0.28137251\n",
      " -0.3304291  -0.3304291  -0.3304291  -0.3304291  -0.29757386 -0.29947082\n",
      " -0.2980023  -0.28599647 -0.22567732 -0.22567732 -0.22567732 -0.22567732\n",
      " -0.22567732 -0.20550694 -0.20225625 -0.20777923 -0.10171162 -0.10171162\n",
      " -0.10171162 -0.10171162 -0.10171162 -0.10171162 -0.10171162 -0.12785913\n",
      " -0.08712093 -0.08712093 -0.08712093 -0.08712093 -0.08712093 -0.08712093\n",
      " -0.08712093 -0.08712093 -0.06552476 -0.06552476 -0.06552476 -0.06552476\n",
      " -0.06552476 -0.06552476 -0.06552476 -0.06552476 -0.03800947 -0.03800947\n",
      " -0.03800947 -0.03800947 -0.03800947 -0.03800947 -0.03800947 -0.03800947\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:21.985497 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:21.986111 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:21.986754 Model DecisionTreeRegressor has been trained for configuration data APII.JK.\n",
      "2023-04-12 08:08:21.987216 Training model based on configuration data: TLKM.JK\n",
      "2023-04-12 08:08:21.987457 Training model: DecisionTreeRegressor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-1.03487042 -1.03487042 -0.99607332 -0.78407039 -0.55943246 -0.49618114\n",
      " -0.43419953 -0.33122851 -0.7976855  -0.7976855  -0.7976855  -0.72210567\n",
      " -0.58779267 -0.48639209 -0.48469995 -0.33347845 -0.41266325 -0.41266325\n",
      " -0.41266325 -0.41266325 -0.36310877 -0.33344755 -0.2748706  -0.14540544\n",
      " -0.22765881 -0.22765881 -0.22765881 -0.22765881 -0.22765881 -0.22565996\n",
      " -0.16826124 -0.10537444 -0.08992162 -0.08992162 -0.08992162 -0.08992162\n",
      " -0.08992162 -0.08992162 -0.08992162 -0.06253527 -0.04580688 -0.04580688\n",
      " -0.04580688 -0.04580688 -0.04580688 -0.04580688 -0.04580688 -0.04580688\n",
      "  0.00561172  0.00561172  0.00561172  0.00561172  0.00561172  0.00561172\n",
      "  0.00561172  0.00561172  0.00734354  0.00734354  0.00734354  0.00734354\n",
      "  0.00734354  0.00734354  0.00734354  0.00734354 -1.03487042 -1.03487042\n",
      " -0.99607332 -0.78407039 -0.55943246 -0.49618114 -0.43419953 -0.33122851\n",
      " -0.7976855  -0.7976855  -0.7976855  -0.72210567 -0.58779267 -0.48639209\n",
      " -0.48469995 -0.33347845 -0.41266325 -0.41266325 -0.41266325 -0.41266325\n",
      " -0.36310877 -0.33344755 -0.2748706  -0.14540544 -0.22765881 -0.22765881\n",
      " -0.22765881 -0.22765881 -0.22765881 -0.22565996 -0.16826124 -0.10537444\n",
      " -0.08992162 -0.08992162 -0.08992162 -0.08992162 -0.08992162 -0.08992162\n",
      " -0.08992162 -0.06253527 -0.04580688 -0.04580688 -0.04580688 -0.04580688\n",
      " -0.04580688 -0.04580688 -0.04580688 -0.04580688  0.00561172  0.00561172\n",
      "  0.00561172  0.00561172  0.00561172  0.00561172  0.00561172  0.00561172\n",
      "  0.00734354  0.00734354  0.00734354  0.00734354  0.00734354  0.00734354\n",
      "  0.00734354  0.00734354 -1.02970653 -1.02970653 -0.92608528 -0.86161066\n",
      " -0.38159647 -0.24994934 -0.19910754 -0.16835683 -0.67494909 -0.67494909\n",
      " -0.67494909 -0.68703557 -0.50014062 -0.40502127 -0.3246916  -0.25248348\n",
      " -0.29562346 -0.29562346 -0.29562346 -0.29562346 -0.27899916 -0.25288095\n",
      " -0.24296234 -0.10111944 -0.17783811 -0.17783811 -0.17783811 -0.17783811\n",
      " -0.17783811 -0.16728043 -0.17662502 -0.09457842 -0.14794399 -0.14794399\n",
      " -0.14794399 -0.14794399 -0.14794399 -0.14794399 -0.14794399 -0.12459318\n",
      " -0.07314813 -0.07314813 -0.07314813 -0.07314813 -0.07314813 -0.07314813\n",
      " -0.07314813 -0.07314813 -0.03345892 -0.03345892 -0.03345892 -0.03345892\n",
      " -0.03345892 -0.03345892 -0.03345892 -0.03345892 -0.01731867 -0.01731867\n",
      " -0.01731867 -0.01731867 -0.01731867 -0.01731867 -0.01731867 -0.01731867\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-04-12 08:08:22.252810 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:22.253410 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:22.254052 Model DecisionTreeRegressor has been trained for configuration data TLKM.JK.\n",
      "2023-04-12 08:08:22.254519 Training model based on configuration data: JKON.JK\n",
      "2023-04-12 08:08:22.254764 Training model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:22.542141 Evalutaing model: DecisionTreeRegressor\n",
      "2023-04-12 08:08:22.542749 Logging: DecisionTreeRegressor\n",
      "2023-04-12 08:08:22.543368 Model DecisionTreeRegressor has been trained for configuration data JKON.JK.\n",
      "2023-04-12 08:08:22.543822 All combination models and configuration data has been trained.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "320 fits failed out of a total of 1280.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "320 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 1247, in fit\n",
      "    super().fit(\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/tree/_classes.py\", line 199, in fit\n",
      "    raise ValueError(\n",
      "ValueError: Some value(s) of y are negative which is not allowed for Poisson regression.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [-1.54175368 -1.54175368 -1.53729139 -1.52040751 -1.26521135 -0.68008659\n",
      " -0.62537579 -0.57699682 -1.32692078 -1.32692078 -1.32692078 -1.2943815\n",
      " -1.12013834 -0.46946819 -0.41568395 -0.36376443 -0.61768742 -0.61768742\n",
      " -0.61768742 -0.61768742 -0.61181859 -0.41696252 -0.39152014 -0.34253609\n",
      " -0.2993456  -0.2993456  -0.2993456  -0.2993456  -0.2993456  -0.26018913\n",
      " -0.24451754 -0.204528   -0.14325008 -0.14325008 -0.14325008 -0.14325008\n",
      " -0.14325008 -0.14325008 -0.14325008 -0.11277302 -0.03857241 -0.03857241\n",
      " -0.03857241 -0.03857241 -0.03857241 -0.03857241 -0.03857241 -0.03857241\n",
      " -0.0623038  -0.0623038  -0.0623038  -0.0623038  -0.0623038  -0.0623038\n",
      " -0.0623038  -0.0623038  -0.07966102 -0.07966102 -0.07966102 -0.07966102\n",
      " -0.07966102 -0.07966102 -0.07966102 -0.07966102 -1.54175368 -1.54175368\n",
      " -1.53729139 -1.52040751 -1.26521135 -0.68008659 -0.62537579 -0.57699682\n",
      " -1.32692078 -1.32692078 -1.32692078 -1.2943815  -1.12013834 -0.46946819\n",
      " -0.41568395 -0.36376443 -0.61768742 -0.61768742 -0.61768742 -0.61768742\n",
      " -0.61181859 -0.41696252 -0.39152014 -0.34253609 -0.2993456  -0.2993456\n",
      " -0.2993456  -0.2993456  -0.2993456  -0.26018913 -0.24451754 -0.204528\n",
      " -0.14325008 -0.14325008 -0.14325008 -0.14325008 -0.14325008 -0.14325008\n",
      " -0.14325008 -0.11277302 -0.03857241 -0.03857241 -0.03857241 -0.03857241\n",
      " -0.03857241 -0.03857241 -0.03857241 -0.03857241 -0.0623038  -0.0623038\n",
      " -0.0623038  -0.0623038  -0.0623038  -0.0623038  -0.0623038  -0.0623038\n",
      " -0.07966102 -0.07966102 -0.07966102 -0.07966102 -0.07966102 -0.07966102\n",
      " -0.07966102 -0.07966102 -1.54766455 -1.54766455 -1.12057409 -0.96273827\n",
      " -0.72932961 -0.49464118 -0.4901345  -0.49640029 -0.8069692  -0.8069692\n",
      " -0.8069692  -0.58684307 -0.51811197 -0.30273797 -0.28645052 -0.29959559\n",
      " -0.29864276 -0.29864276 -0.29864276 -0.29864276 -0.29943422 -0.26665596\n",
      " -0.25231608 -0.25796128 -0.09912821 -0.09912821 -0.09912821 -0.09912821\n",
      " -0.09912821 -0.07992064 -0.07355807 -0.08897939 -0.07770813 -0.07770813\n",
      " -0.07770813 -0.07770813 -0.07770813 -0.07770813 -0.07770813 -0.07675798\n",
      " -0.06349892 -0.06349892 -0.06349892 -0.06349892 -0.06349892 -0.06349892\n",
      " -0.06349892 -0.06349892 -0.07679897 -0.07679897 -0.07679897 -0.07679897\n",
      " -0.07679897 -0.07679897 -0.07679897 -0.07679897 -0.0120546  -0.0120546\n",
      " -0.0120546  -0.0120546  -0.0120546  -0.0120546  -0.0120546  -0.0120546\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan         nan         nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "list_of_trained_model, training_log = train_eval(\"Hyperparams_Tuning\", params, hyper_params_tuning(model))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Take a Look at MSE & Prediction Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_valid, y_valid = load_valid_feng(params)\n",
    "y_pred = model[\"model_data\"][\"model_object\"].predict(x_valid)\n",
    "\n",
    "# Calculate Mean Squared Error\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "\n",
    "# Scatter plot of actual vs. predicted values\n",
    "plt.scatter(y_valid, y_pred, alpha=0.5)\n",
    "plt.xlabel(\"Actual Values\")\n",
    "plt.ylabel(\"Predicted Values\")\n",
    "plt.title(\"Actual vs. Predicted Values\")\n",
    "\n",
    "# Add a diagonal line representing a perfect prediction\n",
    "plt.plot([min(y_valid), max(y_valid)], [min(y_valid), max(y_valid)], color='red', linestyle='--')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_valid, y_valid = load_valid_feng(params)\n",
    "\n",
    "x_train, y_train = load_train_feng(params)\n",
    "\n",
    "# After loading training data\n",
    "print(\"Training data columns:\", x_train.columns)\n",
    "\n",
    "# After loading validation data\n",
    "print(\"Validation data columns:\", x_valid.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After loading training data\n",
    "print(\"Training data shape:\", x_train.shape)\n",
    "\n",
    "# After loading validation data\n",
    "print(\"Validation data shape:\", x_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
